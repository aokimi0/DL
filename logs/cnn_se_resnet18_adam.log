Running Experiment: se_resnet18_adam
Using device: cuda
Running Experiment: se_resnet18_adam
Using device: cuda
Running Experiment: se_resnet18_adam
Using device: cuda
Running Experiment: se_resnet18_adam
Using device: cuda
Running Experiment: se_resnet18_adam
Using device: cuda
Running Experiment: se_resnet18_adam
Using device: cuda
Running Experiment: se_resnet18_adam
Using device: cuda
Using 7 GPUs!
Model Architecture:
DataParallel(
  (module): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (layer1): Sequential(
      (0): SEBasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
        (se): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=64, out_features=4, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=4, out_features=64, bias=False)
            (3): Sigmoid()
          )
        )
      )
      (1): SEBasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
        (se): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=64, out_features=4, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=4, out_features=64, bias=False)
            (3): Sigmoid()
          )
        )
      )
    )
    (layer2): Sequential(
      (0): SEBasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (se): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=128, out_features=8, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=8, out_features=128, bias=False)
            (3): Sigmoid()
          )
        )
      )
      (1): SEBasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
        (se): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=128, out_features=8, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=8, out_features=128, bias=False)
            (3): Sigmoid()
          )
        )
      )
    )
    (layer3): Sequential(
      (0): SEBasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (se): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=256, out_features=16, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=16, out_features=256, bias=False)
            (3): Sigmoid()
          )
        )
      )
      (1): SEBasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
        (se): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=256, out_features=16, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=16, out_features=256, bias=False)
            (3): Sigmoid()
          )
        )
      )
    )
    (layer4): Sequential(
      (0): SEBasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (se): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=512, out_features=32, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=32, out_features=512, bias=False)
            (3): Sigmoid()
          )
        )
      )
      (1): SEBasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
        (se): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=512, out_features=32, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=32, out_features=512, bias=False)
            (3): Sigmoid()
          )
        )
      )
    )
    (linear): Linear(in_features=512, out_features=10, bias=True)
  )
)

Optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    decoupled_weight_decay: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
Using 7 GPUs!
Model Architecture:
DataParallel(
  (module): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (layer1): Sequential(
      (0): SEBasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
        (se): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=64, out_features=4, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=4, out_features=64, bias=False)
            (3): Sigmoid()
          )
        )
      )
      (1): SEBasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
        (se): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=64, out_features=4, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=4, out_features=64, bias=False)
            (3): Sigmoid()
          )
        )
      )
    )
    (layer2): Sequential(
      (0): SEBasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (se): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=128, out_features=8, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=8, out_features=128, bias=False)
            (3): Sigmoid()
          )
        )
      )
      (1): SEBasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
        (se): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=128, out_features=8, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=8, out_features=128, bias=False)
            (3): Sigmoid()
          )
        )
      )
    )
    (layer3): Sequential(
      (0): SEBasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (se): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=256, out_features=16, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=16, out_features=256, bias=False)
            (3): Sigmoid()
          )
        )
      )
      (1): SEBasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
        (se): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=256, out_features=16, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=16, out_features=256, bias=False)
            (3): Sigmoid()
          )
        )
      )
    )
    (layer4): Sequential(
      (0): SEBasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (se): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=512, out_features=32, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=32, out_features=512, bias=False)
            (3): Sigmoid()
          )
        )
      )
      (1): SEBasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
        (se): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=512, out_features=32, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=32, out_features=512, bias=False)
            (3): Sigmoid()
          )
        )
      )
    )
    (linear): Linear(in_features=512, out_features=10, bias=True)
  )
)

Optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    decoupled_weight_decay: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
Using 7 GPUs!
Model Architecture:
Using 7 GPUs!
DataParallel(
  (module): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (layer1): Sequential(
      (0): SEBasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
        (se): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=64, out_features=4, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=4, out_features=64, bias=False)
            (3): Sigmoid()
          )
        )
      )
      (1): SEBasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
        (se): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=64, out_features=4, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=4, out_features=64, bias=False)
            (3): Sigmoid()
          )
        )
      )
    )
    (layer2): Sequential(
      (0): SEBasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (se): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=128, out_features=8, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=8, out_features=128, bias=False)
            (3): Sigmoid()
          )
        )
      )
      (1): SEBasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
        (se): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=128, out_features=8, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=8, out_features=128, bias=False)
            (3): Sigmoid()
          )
        )
      )
    )
    (layer3): Sequential(
      (0): SEBasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (se): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=256, out_features=16, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=16, out_features=256, bias=False)
            (3): Sigmoid()
          )
        )
      )
      (1): SEBasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
        (se): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=256, out_features=16, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=16, out_features=256, bias=False)
            (3): Sigmoid()
          )
        )
      )
    )
    (layer4): Sequential(
      (0): SEBasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (se): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=512, out_features=32, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=32, out_features=512, bias=False)
            (3): Sigmoid()
          )
        )
      )
      (1): SEBasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
        (se): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=512, out_features=32, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=32, out_features=512, bias=False)
            (3): Sigmoid()
          )
        )
      )
    )
    (linear): Linear(in_features=512, out_features=10, bias=True)
  )
)

Optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    decoupled_weight_decay: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
Model Architecture:
DataParallel(
  (module): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (layer1): Sequential(
      (0): SEBasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
        (se): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=64, out_features=4, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=4, out_features=64, bias=False)
            (3): Sigmoid()
          )
        )
      )
      (1): SEBasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
        (se): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=64, out_features=4, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=4, out_features=64, bias=False)
            (3): Sigmoid()
          )
        )
      )
    )
    (layer2): Sequential(
      (0): SEBasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (se): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=128, out_features=8, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=8, out_features=128, bias=False)
            (3): Sigmoid()
          )
        )
      )
      (1): SEBasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
        (se): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=128, out_features=8, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=8, out_features=128, bias=False)
            (3): Sigmoid()
          )
        )
      )
    )
    (layer3): Sequential(
      (0): SEBasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (se): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=256, out_features=16, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=16, out_features=256, bias=False)
            (3): Sigmoid()
          )
        )
      )
      (1): SEBasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
        (se): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=256, out_features=16, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=16, out_features=256, bias=False)
            (3): Sigmoid()
          )
        )
      )
    )
    (layer4): Sequential(
      (0): SEBasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (se): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=512, out_features=32, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=32, out_features=512, bias=False)
            (3): Sigmoid()
          )
        )
      )
      (1): SEBasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
        (se): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=512, out_features=32, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=32, out_features=512, bias=False)
            (3): Sigmoid()
          )
        )
      )
    )
    (linear): Linear(in_features=512, out_features=10, bias=True)
  )
)

Optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    decoupled_weight_decay: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
Using 7 GPUs!
Using 7 GPUs!
Model Architecture:
Model Architecture:
DataParallel(
  (module): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (layer1): Sequential(
      (0): SEBasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
        (se): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=64, out_features=4, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=4, out_features=64, bias=False)
            (3): Sigmoid()
          )
        )
      )
      (1): SEBasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
        (se): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=64, out_features=4, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=4, out_features=64, bias=False)
            (3): Sigmoid()
          )
        )
      )
    )
    (layer2): Sequential(
      (0): SEBasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (se): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=128, out_features=8, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=8, out_features=128, bias=False)
            (3): Sigmoid()
          )
        )
      )
      (1): SEBasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
        (se): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=128, out_features=8, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=8, out_features=128, bias=False)
            (3): Sigmoid()
          )
        )
      )
    )
    (layer3): Sequential(
      (0): SEBasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (se): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=256, out_features=16, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=16, out_features=256, bias=False)
            (3): Sigmoid()
          )
        )
      )
      (1): SEBasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
        (se): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=256, out_features=16, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=16, out_features=256, bias=False)
            (3): Sigmoid()
          )
        )
      )
    )
    (layer4): Sequential(
      (0): SEBasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (se): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=512, out_features=32, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=32, out_features=512, bias=False)
            (3): Sigmoid()
          )
        )
      )
      (1): SEBasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
        (se): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=512, out_features=32, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=32, out_features=512, bias=False)
            (3): Sigmoid()
          )
        )
      )
    )
    (linear): Linear(in_features=512, out_features=10, bias=True)
  )
)

Optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    decoupled_weight_decay: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
DataParallel(
  (module): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (layer1): Sequential(
      (0): SEBasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
        (se): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=64, out_features=4, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=4, out_features=64, bias=False)
            (3): Sigmoid()
          )
        )
      )
      (1): SEBasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
        (se): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=64, out_features=4, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=4, out_features=64, bias=False)
            (3): Sigmoid()
          )
        )
      )
    )
    (layer2): Sequential(
      (0): SEBasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (se): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=128, out_features=8, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=8, out_features=128, bias=False)
            (3): Sigmoid()
          )
        )
      )
      (1): SEBasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
        (se): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=128, out_features=8, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=8, out_features=128, bias=False)
            (3): Sigmoid()
          )
        )
      )
    )
    (layer3): Sequential(
      (0): SEBasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (se): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=256, out_features=16, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=16, out_features=256, bias=False)
            (3): Sigmoid()
          )
        )
      )
      (1): SEBasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
        (se): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=256, out_features=16, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=16, out_features=256, bias=False)
            (3): Sigmoid()
          )
        )
      )
    )
    (layer4): Sequential(
      (0): SEBasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (se): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=512, out_features=32, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=32, out_features=512, bias=False)
            (3): Sigmoid()
          )
        )
      )
      (1): SEBasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
        (se): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=512, out_features=32, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=32, out_features=512, bias=False)
            (3): Sigmoid()
          )
        )
      )
    )
    (linear): Linear(in_features=512, out_features=10, bias=True)
  )
)

Optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    decoupled_weight_decay: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
Using 7 GPUs!
Model Architecture:
DataParallel(
  (module): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (layer1): Sequential(
      (0): SEBasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
        (se): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=64, out_features=4, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=4, out_features=64, bias=False)
            (3): Sigmoid()
          )
        )
      )
      (1): SEBasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
        (se): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=64, out_features=4, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=4, out_features=64, bias=False)
            (3): Sigmoid()
          )
        )
      )
    )
    (layer2): Sequential(
      (0): SEBasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (se): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=128, out_features=8, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=8, out_features=128, bias=False)
            (3): Sigmoid()
          )
        )
      )
      (1): SEBasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
        (se): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=128, out_features=8, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=8, out_features=128, bias=False)
            (3): Sigmoid()
          )
        )
      )
    )
    (layer3): Sequential(
      (0): SEBasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (se): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=256, out_features=16, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=16, out_features=256, bias=False)
            (3): Sigmoid()
          )
        )
      )
      (1): SEBasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
        (se): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=256, out_features=16, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=16, out_features=256, bias=False)
            (3): Sigmoid()
          )
        )
      )
    )
    (layer4): Sequential(
      (0): SEBasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (se): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=512, out_features=32, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=32, out_features=512, bias=False)
            (3): Sigmoid()
          )
        )
      )
      (1): SEBasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
        (se): SEBlock(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=512, out_features=32, bias=False)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=32, out_features=512, bias=False)
            (3): Sigmoid()
          )
        )
      )
    )
    (linear): Linear(in_features=512, out_features=10, bias=True)
  )
)

Optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    decoupled_weight_decay: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
Train Epoch: 1 [0/50000 (0%)]	Loss: 2.324347
Train Epoch: 1 [0/50000 (0%)]	Loss: 2.391840
Train Epoch: 1 [0/50000 (0%)]	Loss: 2.340231
Train Epoch: 1 [0/50000 (0%)]	Loss: 2.379235
Train Epoch: 1 [0/50000 (0%)]	Loss: 2.331269
Train Epoch: 1 [0/50000 (0%)]	Loss: 2.359893
Train Epoch: 1 [0/50000 (0%)]	Loss: 2.331988
Train Epoch: 1 [25600/50000 (51%)]	Loss: 1.301615
Train Epoch: 1 [25600/50000 (51%)]	Loss: 1.161197
Train Epoch: 1 [25600/50000 (51%)]	Loss: 1.344061
Train Epoch: 1 [25600/50000 (51%)]	Loss: 1.064327
Train Epoch: 1 [25600/50000 (51%)]	Loss: 1.302341
Train Epoch: 1 [25600/50000 (51%)]	Loss: 1.201561
Train Epoch: 1 [25600/50000 (51%)]	Loss: 1.140515

Validation set: Average loss: 1.2884, Accuracy: 5677/10000 (57%)

Train Epoch: 2 [0/50000 (0%)]	Loss: 0.813023

Validation set: Average loss: 1.0351, Accuracy: 6271/10000 (63%)


Validation set: Average loss: 0.9988, Accuracy: 6483/10000 (65%)

Train Epoch: 2 [0/50000 (0%)]	Loss: 0.876860
Train Epoch: 2 [0/50000 (0%)]	Loss: 0.933203

Validation set: Average loss: 1.3550, Accuracy: 5334/10000 (53%)


Validation set: Average loss: 1.0930, Accuracy: 6084/10000 (61%)

Train Epoch: 2 [0/50000 (0%)]	Loss: 0.882618
Train Epoch: 2 [0/50000 (0%)]	Loss: 0.932838

Validation set: Average loss: 1.1000, Accuracy: 5990/10000 (60%)

Train Epoch: 2 [0/50000 (0%)]	Loss: 0.976991

Validation set: Average loss: 1.1126, Accuracy: 6005/10000 (60%)

Train Epoch: 2 [0/50000 (0%)]	Loss: 1.039496
Train Epoch: 2 [25600/50000 (51%)]	Loss: 0.916743
Train Epoch: 2 [25600/50000 (51%)]	Loss: 0.840205
Train Epoch: 2 [25600/50000 (51%)]	Loss: 0.750824
Train Epoch: 2 [25600/50000 (51%)]	Loss: 0.821858
Train Epoch: 2 [25600/50000 (51%)]	Loss: 0.736926
Train Epoch: 2 [25600/50000 (51%)]	Loss: 0.943420
Train Epoch: 2 [25600/50000 (51%)]	Loss: 0.776277

Validation set: Average loss: 0.9093, Accuracy: 6844/10000 (68%)

Train Epoch: 3 [0/50000 (0%)]	Loss: 0.609459

Validation set: Average loss: 0.8132, Accuracy: 7143/10000 (71%)


Validation set: Average loss: 0.8626, Accuracy: 6871/10000 (69%)

Train Epoch: 3 [0/50000 (0%)]	Loss: 0.650167
Train Epoch: 3 [0/50000 (0%)]	Loss: 0.694033

Validation set: Average loss: 0.7725, Accuracy: 7253/10000 (73%)

Train Epoch: 3 [0/50000 (0%)]	Loss: 0.570345

Validation set: Average loss: 0.9304, Accuracy: 6749/10000 (67%)

Train Epoch: 3 [0/50000 (0%)]	Loss: 0.677940

Validation set: Average loss: 0.8037, Accuracy: 7162/10000 (72%)

Train Epoch: 3 [0/50000 (0%)]	Loss: 0.669754

Validation set: Average loss: 0.8205, Accuracy: 7100/10000 (71%)

Train Epoch: 3 [0/50000 (0%)]	Loss: 0.532014
Train Epoch: 3 [25600/50000 (51%)]	Loss: 0.585064
Train Epoch: 3 [25600/50000 (51%)]	Loss: 0.588413
Train Epoch: 3 [25600/50000 (51%)]	Loss: 0.597164
Train Epoch: 3 [25600/50000 (51%)]	Loss: 0.617003
Train Epoch: 3 [25600/50000 (51%)]	Loss: 0.682278
Train Epoch: 3 [25600/50000 (51%)]	Loss: 0.671447
Train Epoch: 3 [25600/50000 (51%)]	Loss: 0.627434

Validation set: Average loss: 0.6847, Accuracy: 7676/10000 (77%)

Train Epoch: 4 [0/50000 (0%)]	Loss: 0.404283

Validation set: Average loss: 0.7091, Accuracy: 7615/10000 (76%)


Validation set: Average loss: 0.6816, Accuracy: 7653/10000 (77%)

Train Epoch: 4 [0/50000 (0%)]	Loss: 0.446928
Train Epoch: 4 [0/50000 (0%)]	Loss: 0.463350

Validation set: Average loss: 0.7609, Accuracy: 7379/10000 (74%)


Validation set: Average loss: 0.7857, Accuracy: 7321/10000 (73%)

Train Epoch: 4 [0/50000 (0%)]	Loss: 0.491675
Train Epoch: 4 [0/50000 (0%)]	Loss: 0.492431

Validation set: Average loss: 0.6929, Accuracy: 7626/10000 (76%)

Train Epoch: 4 [0/50000 (0%)]	Loss: 0.430010

Validation set: Average loss: 0.6863, Accuracy: 7606/10000 (76%)

Train Epoch: 4 [0/50000 (0%)]	Loss: 0.570091
Train Epoch: 4 [25600/50000 (51%)]	Loss: 0.520129
Train Epoch: 4 [25600/50000 (51%)]	Loss: 0.440882
Train Epoch: 4 [25600/50000 (51%)]	Loss: 0.558744
Train Epoch: 4 [25600/50000 (51%)]	Loss: 0.387519
Train Epoch: 4 [25600/50000 (51%)]	Loss: 0.350445
Train Epoch: 4 [25600/50000 (51%)]	Loss: 0.495947
Train Epoch: 4 [25600/50000 (51%)]	Loss: 0.415610

Validation set: Average loss: 0.6344, Accuracy: 7855/10000 (79%)

Train Epoch: 5 [0/50000 (0%)]	Loss: 0.347758

Validation set: Average loss: 0.6577, Accuracy: 7775/10000 (78%)

Train Epoch: 5 [0/50000 (0%)]	Loss: 0.299441

Validation set: Average loss: 0.6556, Accuracy: 7768/10000 (78%)

Train Epoch: 5 [0/50000 (0%)]	Loss: 0.365418

Validation set: Average loss: 0.6528, Accuracy: 7857/10000 (79%)

Train Epoch: 5 [0/50000 (0%)]	Loss: 0.340958

Validation set: Average loss: 0.6670, Accuracy: 7760/10000 (78%)

Train Epoch: 5 [0/50000 (0%)]	Loss: 0.364148

Validation set: Average loss: 0.9166, Accuracy: 7034/10000 (70%)

Train Epoch: 5 [0/50000 (0%)]	Loss: 0.357490

Validation set: Average loss: 0.6076, Accuracy: 7944/10000 (79%)

Train Epoch: 5 [0/50000 (0%)]	Loss: 0.378763
Train Epoch: 5 [25600/50000 (51%)]	Loss: 0.316878
Train Epoch: 5 [25600/50000 (51%)]	Loss: 0.313432
Train Epoch: 5 [25600/50000 (51%)]	Loss: 0.406867
Train Epoch: 5 [25600/50000 (51%)]	Loss: 0.354129
Train Epoch: 5 [25600/50000 (51%)]	Loss: 0.329589
Train Epoch: 5 [25600/50000 (51%)]	Loss: 0.352987
Train Epoch: 5 [25600/50000 (51%)]	Loss: 0.373410

Validation set: Average loss: 0.6019, Accuracy: 8047/10000 (80%)

Train Epoch: 6 [0/50000 (0%)]	Loss: 0.303491

Validation set: Average loss: 0.6233, Accuracy: 7998/10000 (80%)

Train Epoch: 6 [0/50000 (0%)]	Loss: 0.232078

Validation set: Average loss: 0.6301, Accuracy: 7922/10000 (79%)

Train Epoch: 6 [0/50000 (0%)]	Loss: 0.241796

Validation set: Average loss: 0.5750, Accuracy: 8086/10000 (81%)


Validation set: Average loss: 0.6199, Accuracy: 7976/10000 (80%)

Train Epoch: 6 [0/50000 (0%)]	Loss: 0.219169
Train Epoch: 6 [0/50000 (0%)]	Loss: 0.329062

Validation set: Average loss: 0.6077, Accuracy: 8022/10000 (80%)

Train Epoch: 6 [0/50000 (0%)]	Loss: 0.217944

Validation set: Average loss: 0.6413, Accuracy: 7862/10000 (79%)

Train Epoch: 6 [0/50000 (0%)]	Loss: 0.231516
Train Epoch: 6 [25600/50000 (51%)]	Loss: 0.261776
Train Epoch: 6 [25600/50000 (51%)]	Loss: 0.259342
Train Epoch: 6 [25600/50000 (51%)]	Loss: 0.299293
Train Epoch: 6 [25600/50000 (51%)]	Loss: 0.346100
Train Epoch: 6 [25600/50000 (51%)]	Loss: 0.253587
Train Epoch: 6 [25600/50000 (51%)]	Loss: 0.289646
Train Epoch: 6 [25600/50000 (51%)]	Loss: 0.273469

Validation set: Average loss: 0.7342, Accuracy: 7798/10000 (78%)

Train Epoch: 7 [0/50000 (0%)]	Loss: 0.240161

Validation set: Average loss: 0.6751, Accuracy: 7951/10000 (80%)

Train Epoch: 7 [0/50000 (0%)]	Loss: 0.148614

Validation set: Average loss: 0.5948, Accuracy: 8143/10000 (81%)

Train Epoch: 7 [0/50000 (0%)]	Loss: 0.229642

Validation set: Average loss: 0.6081, Accuracy: 8119/10000 (81%)


Validation set: Average loss: 0.6956, Accuracy: 7840/10000 (78%)

Train Epoch: 7 [0/50000 (0%)]	Loss: 0.219149
Train Epoch: 7 [0/50000 (0%)]	Loss: 0.179903

Validation set: Average loss: 0.6591, Accuracy: 7989/10000 (80%)

Train Epoch: 7 [0/50000 (0%)]	Loss: 0.150115

Validation set: Average loss: 0.6072, Accuracy: 8087/10000 (81%)

Train Epoch: 7 [0/50000 (0%)]	Loss: 0.183097
Train Epoch: 7 [25600/50000 (51%)]	Loss: 0.131529
Train Epoch: 7 [25600/50000 (51%)]	Loss: 0.190732
Train Epoch: 7 [25600/50000 (51%)]	Loss: 0.230328
Train Epoch: 7 [25600/50000 (51%)]	Loss: 0.160529
Train Epoch: 7 [25600/50000 (51%)]	Loss: 0.166172
Train Epoch: 7 [25600/50000 (51%)]	Loss: 0.239599
Train Epoch: 7 [25600/50000 (51%)]	Loss: 0.177135

Validation set: Average loss: 0.6386, Accuracy: 8182/10000 (82%)

Train Epoch: 8 [0/50000 (0%)]	Loss: 0.147358

Validation set: Average loss: 0.7016, Accuracy: 8032/10000 (80%)

Train Epoch: 8 [0/50000 (0%)]	Loss: 0.102969

Validation set: Average loss: 0.6511, Accuracy: 8108/10000 (81%)

Train Epoch: 8 [0/50000 (0%)]	Loss: 0.135527

Validation set: Average loss: 0.7405, Accuracy: 7931/10000 (79%)


Validation set: Average loss: 0.7423, Accuracy: 7994/10000 (80%)

Train Epoch: 8 [0/50000 (0%)]	Loss: 0.141921
Train Epoch: 8 [0/50000 (0%)]	Loss: 0.095885

Validation set: Average loss: 0.6923, Accuracy: 7947/10000 (79%)

Train Epoch: 8 [0/50000 (0%)]	Loss: 0.129507

Validation set: Average loss: 0.7296, Accuracy: 7997/10000 (80%)

Train Epoch: 8 [0/50000 (0%)]	Loss: 0.118586
Train Epoch: 8 [25600/50000 (51%)]	Loss: 0.088013
Train Epoch: 8 [25600/50000 (51%)]	Loss: 0.193493
Train Epoch: 8 [25600/50000 (51%)]	Loss: 0.119247
Train Epoch: 8 [25600/50000 (51%)]	Loss: 0.070571
Train Epoch: 8 [25600/50000 (51%)]	Loss: 0.086341
Train Epoch: 8 [25600/50000 (51%)]	Loss: 0.119280
Train Epoch: 8 [25600/50000 (51%)]	Loss: 0.128979

Validation set: Average loss: 0.7982, Accuracy: 7912/10000 (79%)

Train Epoch: 9 [0/50000 (0%)]	Loss: 0.084668

Validation set: Average loss: 0.6718, Accuracy: 8156/10000 (82%)

Train Epoch: 9 [0/50000 (0%)]	Loss: 0.057877

Validation set: Average loss: 0.6322, Accuracy: 8225/10000 (82%)

Train Epoch: 9 [0/50000 (0%)]	Loss: 0.170505

Validation set: Average loss: 0.6956, Accuracy: 8153/10000 (82%)


Validation set: Average loss: 0.6919, Accuracy: 8084/10000 (81%)

Train Epoch: 9 [0/50000 (0%)]	Loss: 0.096717
Train Epoch: 9 [0/50000 (0%)]	Loss: 0.114289

Validation set: Average loss: 0.7012, Accuracy: 8019/10000 (80%)

Train Epoch: 9 [0/50000 (0%)]	Loss: 0.049620

Validation set: Average loss: 0.6952, Accuracy: 8168/10000 (82%)

Train Epoch: 9 [0/50000 (0%)]	Loss: 0.096807
Train Epoch: 9 [25600/50000 (51%)]	Loss: 0.064657
Train Epoch: 9 [25600/50000 (51%)]	Loss: 0.094627
Train Epoch: 9 [25600/50000 (51%)]	Loss: 0.119115
Train Epoch: 9 [25600/50000 (51%)]	Loss: 0.063374
Train Epoch: 9 [25600/50000 (51%)]	Loss: 0.108895
Train Epoch: 9 [25600/50000 (51%)]	Loss: 0.070000
Train Epoch: 9 [25600/50000 (51%)]	Loss: 0.085285

Validation set: Average loss: 0.6701, Accuracy: 8188/10000 (82%)

Train Epoch: 10 [0/50000 (0%)]	Loss: 0.057484

Validation set: Average loss: 0.8829, Accuracy: 7964/10000 (80%)

Train Epoch: 10 [0/50000 (0%)]	Loss: 0.084862

Validation set: Average loss: 0.8611, Accuracy: 7899/10000 (79%)

Train Epoch: 10 [0/50000 (0%)]	Loss: 0.053484

Validation set: Average loss: 0.7197, Accuracy: 8181/10000 (82%)


Validation set: Average loss: 0.8217, Accuracy: 8068/10000 (81%)

Train Epoch: 10 [0/50000 (0%)]	Loss: 0.066590
Train Epoch: 10 [0/50000 (0%)]	Loss: 0.136869

Validation set: Average loss: 0.6908, Accuracy: 8274/10000 (83%)

Train Epoch: 10 [0/50000 (0%)]	Loss: 0.107010

Validation set: Average loss: 0.7074, Accuracy: 8188/10000 (82%)

Train Epoch: 10 [0/50000 (0%)]	Loss: 0.078480
Train Epoch: 10 [25600/50000 (51%)]	Loss: 0.031264
Train Epoch: 10 [25600/50000 (51%)]	Loss: 0.061758
Train Epoch: 10 [25600/50000 (51%)]	Loss: 0.076423
Train Epoch: 10 [25600/50000 (51%)]	Loss: 0.109485
Train Epoch: 10 [25600/50000 (51%)]	Loss: 0.093644
Train Epoch: 10 [25600/50000 (51%)]	Loss: 0.050088
Train Epoch: 10 [25600/50000 (51%)]	Loss: 0.047212

Validation set: Average loss: 0.7091, Accuracy: 8271/10000 (83%)

性能图表已保存至: fig/cnn/se_resnet18_adam/performance_se_resnet18_adam.png
Model saved to out/cnn/se_resnet18_adam/model.pth

Validation set: Average loss: 0.7853, Accuracy: 8082/10000 (81%)

性能图表已保存至: fig/cnn/se_resnet18_adam/performance_se_resnet18_adam.png
Model saved to out/cnn/se_resnet18_adam/model.pth

Validation set: Average loss: 0.8604, Accuracy: 7945/10000 (79%)

性能图表已保存至: fig/cnn/se_resnet18_adam/performance_se_resnet18_adam.png
Model saved to out/cnn/se_resnet18_adam/model.pth

Validation set: Average loss: 0.8691, Accuracy: 8069/10000 (81%)


Validation set: Average loss: 0.7494, Accuracy: 8183/10000 (82%)

性能图表已保存至: fig/cnn/se_resnet18_adam/performance_se_resnet18_adam.png
Model saved to out/cnn/se_resnet18_adam/model.pth
性能图表已保存至: fig/cnn/se_resnet18_adam/performance_se_resnet18_adam.png
Model saved to out/cnn/se_resnet18_adam/model.pth
