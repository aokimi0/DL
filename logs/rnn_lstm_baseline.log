Running Experiment: lstm_baseline
Using device: cuda
Running Experiment: lstm_baseline
Using device: cuda
Running Experiment: lstm_baseline
Using device: cuda
Running Experiment: lstm_baseline
Using device: cuda
Running Experiment: lstm_baseline
Using device: cuda
Running Experiment: lstm_baseline
Using device: cuda
Running Experiment: lstm_baseline
Using device: cuda
Using 7 GPUs!
Model Architecture:
DataParallel(
  (module): BaselineLSTM(
    (lstm): LSTM(28, 128, num_layers=2, batch_first=True)
    (fc): Linear(in_features=128, out_features=10, bias=True)
  )
)

Optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    decoupled_weight_decay: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
Using 7 GPUs!
Model Architecture:
DataParallel(
  (module): BaselineLSTM(
    (lstm): LSTM(28, 128, num_layers=2, batch_first=True)
    (fc): Linear(in_features=128, out_features=10, bias=True)
  )
)

Optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    decoupled_weight_decay: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
Using 7 GPUs!
Model Architecture:
DataParallel(
  (module): BaselineLSTM(
    (lstm): LSTM(28, 128, num_layers=2, batch_first=True)
    (fc): Linear(in_features=128, out_features=10, bias=True)
  )
)

Optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    decoupled_weight_decay: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
Using 7 GPUs!
Model Architecture:
DataParallel(
  (module): BaselineLSTM(
    (lstm): LSTM(28, 128, num_layers=2, batch_first=True)
    (fc): Linear(in_features=128, out_features=10, bias=True)
  )
)

Optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    decoupled_weight_decay: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
Using 7 GPUs!
Model Architecture:
DataParallel(
  (module): BaselineLSTM(
    (lstm): LSTM(28, 128, num_layers=2, batch_first=True)
    (fc): Linear(in_features=128, out_features=10, bias=True)
  )
)

Optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    decoupled_weight_decay: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
Using 7 GPUs!
Model Architecture:
DataParallel(
  (module): BaselineLSTM(
    (lstm): LSTM(28, 128, num_layers=2, batch_first=True)
    (fc): Linear(in_features=128, out_features=10, bias=True)
  )
)

Optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    decoupled_weight_decay: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
Using 7 GPUs!
Model Architecture:
DataParallel(
  (module): BaselineLSTM(
    (lstm): LSTM(28, 128, num_layers=2, batch_first=True)
    (fc): Linear(in_features=128, out_features=10, bias=True)
  )
)

Optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    decoupled_weight_decay: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
Train Epoch: 1 [0/60000 (0%)]	Loss: 2.311967
Train Epoch: 1 [0/60000 (0%)]	Loss: 2.302422
Train Epoch: 1 [0/60000 (0%)]	Loss: 2.301846
Train Epoch: 1 [0/60000 (0%)]	Loss: 2.299253
Train Epoch: 1 [0/60000 (0%)]	Loss: 2.304245
Train Epoch: 1 [0/60000 (0%)]	Loss: 2.300107
Train Epoch: 1 [0/60000 (0%)]	Loss: 2.308873
Train Epoch: 1 [12800/60000 (21%)]	Loss: 0.466419
Train Epoch: 1 [12800/60000 (21%)]	Loss: 0.372457
Train Epoch: 1 [12800/60000 (21%)]	Loss: 0.577899
Train Epoch: 1 [12800/60000 (21%)]	Loss: 0.379481
Train Epoch: 1 [12800/60000 (21%)]	Loss: 0.440029
Train Epoch: 1 [12800/60000 (21%)]	Loss: 0.453610
Train Epoch: 1 [12800/60000 (21%)]	Loss: 0.526389
Train Epoch: 1 [25600/60000 (43%)]	Loss: 0.170830
Train Epoch: 1 [25600/60000 (43%)]	Loss: 0.158816
Train Epoch: 1 [25600/60000 (43%)]	Loss: 0.308579
Train Epoch: 1 [25600/60000 (43%)]	Loss: 0.162841
Train Epoch: 1 [25600/60000 (43%)]	Loss: 0.217268
Train Epoch: 1 [25600/60000 (43%)]	Loss: 0.281478
Train Epoch: 1 [25600/60000 (43%)]	Loss: 0.136773
Train Epoch: 1 [38400/60000 (64%)]	Loss: 0.119035
Train Epoch: 1 [38400/60000 (64%)]	Loss: 0.216091
Train Epoch: 1 [38400/60000 (64%)]	Loss: 0.173477
Train Epoch: 1 [38400/60000 (64%)]	Loss: 0.112455
Train Epoch: 1 [38400/60000 (64%)]	Loss: 0.113892
Train Epoch: 1 [38400/60000 (64%)]	Loss: 0.143329
Train Epoch: 1 [38400/60000 (64%)]	Loss: 0.190935
Train Epoch: 1 [51200/60000 (85%)]	Loss: 0.077810
Train Epoch: 1 [51200/60000 (85%)]	Loss: 0.068711
Train Epoch: 1 [51200/60000 (85%)]	Loss: 0.099022
Train Epoch: 1 [51200/60000 (85%)]	Loss: 0.226325
Train Epoch: 1 [51200/60000 (85%)]	Loss: 0.071090
Train Epoch: 1 [51200/60000 (85%)]	Loss: 0.144537
Train Epoch: 1 [51200/60000 (85%)]	Loss: 0.099037

Validation set: Average loss: 0.1211, Accuracy: 9632/10000 (96%)


Validation set: Average loss: 0.1388, Accuracy: 9563/10000 (96%)

Train Epoch: 2 [0/60000 (0%)]	Loss: 0.090125

Validation set: Average loss: 0.1350, Accuracy: 9581/10000 (96%)

Train Epoch: 2 [0/60000 (0%)]	Loss: 0.111923
Train Epoch: 2 [0/60000 (0%)]	Loss: 0.084128

Validation set: Average loss: 0.1002, Accuracy: 9702/10000 (97%)


Validation set: Average loss: 0.0997, Accuracy: 9697/10000 (97%)

Train Epoch: 2 [0/60000 (0%)]	Loss: 0.079410

Validation set: Average loss: 0.1225, Accuracy: 9632/10000 (96%)


Validation set: Average loss: 0.1368, Accuracy: 9590/10000 (96%)

Train Epoch: 2 [0/60000 (0%)]	Loss: 0.104762
Train Epoch: 2 [0/60000 (0%)]	Loss: 0.142837
Train Epoch: 2 [0/60000 (0%)]	Loss: 0.182956
Train Epoch: 2 [12800/60000 (21%)]	Loss: 0.106021
Train Epoch: 2 [12800/60000 (21%)]	Loss: 0.062805
Train Epoch: 2 [12800/60000 (21%)]	Loss: 0.116944
Train Epoch: 2 [12800/60000 (21%)]	Loss: 0.069401
Train Epoch: 2 [12800/60000 (21%)]	Loss: 0.103140
Train Epoch: 2 [12800/60000 (21%)]	Loss: 0.192696
Train Epoch: 2 [12800/60000 (21%)]	Loss: 0.081470
Train Epoch: 2 [25600/60000 (43%)]	Loss: 0.100569
Train Epoch: 2 [25600/60000 (43%)]	Loss: 0.167270
Train Epoch: 2 [25600/60000 (43%)]	Loss: 0.031552
Train Epoch: 2 [25600/60000 (43%)]	Loss: 0.066606
Train Epoch: 2 [25600/60000 (43%)]	Loss: 0.131610
Train Epoch: 2 [25600/60000 (43%)]	Loss: 0.070597
Train Epoch: 2 [25600/60000 (43%)]	Loss: 0.043509
Train Epoch: 2 [38400/60000 (64%)]	Loss: 0.084379
Train Epoch: 2 [38400/60000 (64%)]	Loss: 0.093751
Train Epoch: 2 [38400/60000 (64%)]	Loss: 0.069204
Train Epoch: 2 [38400/60000 (64%)]	Loss: 0.103914
Train Epoch: 2 [38400/60000 (64%)]	Loss: 0.111662
Train Epoch: 2 [38400/60000 (64%)]	Loss: 0.012763
Train Epoch: 2 [38400/60000 (64%)]	Loss: 0.156377
Train Epoch: 2 [51200/60000 (85%)]	Loss: 0.078975
Train Epoch: 2 [51200/60000 (85%)]	Loss: 0.095990
Train Epoch: 2 [51200/60000 (85%)]	Loss: 0.066069
Train Epoch: 2 [51200/60000 (85%)]	Loss: 0.125151
Train Epoch: 2 [51200/60000 (85%)]	Loss: 0.095942
Train Epoch: 2 [51200/60000 (85%)]	Loss: 0.081462
Train Epoch: 2 [51200/60000 (85%)]	Loss: 0.066081

Validation set: Average loss: 0.0676, Accuracy: 9809/10000 (98%)

Train Epoch: 3 [0/60000 (0%)]	Loss: 0.026574

Validation set: Average loss: 0.0737, Accuracy: 9784/10000 (98%)

Train Epoch: 3 [0/60000 (0%)]	Loss: 0.110858

Validation set: Average loss: 0.0770, Accuracy: 9779/10000 (98%)


Validation set: Average loss: 0.0730, Accuracy: 9771/10000 (98%)


Validation set: Average loss: 0.0797, Accuracy: 9760/10000 (98%)


Validation set: Average loss: 0.0723, Accuracy: 9792/10000 (98%)

Train Epoch: 3 [0/60000 (0%)]	Loss: 0.021281

Validation set: Average loss: 0.0828, Accuracy: 9769/10000 (98%)

Train Epoch: 3 [0/60000 (0%)]	Loss: 0.061607
Train Epoch: 3 [0/60000 (0%)]	Loss: 0.042466
Train Epoch: 3 [0/60000 (0%)]	Loss: 0.101571
Train Epoch: 3 [0/60000 (0%)]	Loss: 0.088008
